{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>Laboratorio 9:  ¬øSuperh√©roe o Villano?  ü¶¥</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"
      ],
      "metadata": {
        "id": "XUZ1dFPHzAHl",
        "cell_id": "97c30de09ab74ff8a8ead49b42589d52",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Pablo Badilla y Ignacio Meza\n",
        "- Auxiliar: Sebasti√°n Tinoco\n",
        "- Ayudante: Felipe Arias y Diego Cortez"
      ],
      "metadata": {
        "id": "UD8X1uhGzAHq",
        "cell_id": "44f0e095cf894684b9513510e9517584",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Gabriela Mora\n",
        "- Nombre de alumno 2: Ra√∫l Silva\n"
      ],
      "metadata": {
        "id": "tXflExjqzAHr",
        "cell_id": "630dba7238124007a872bee8e5ac1068",
        "deepnote_cell_height": 171.78125,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/RaulSilvaA/MDS7202-mora-silva`"
      ],
      "metadata": {
        "id": "AD-V0bbZzAHr",
        "cell_id": "b3307d6b91384799b5ffb79d87b50821",
        "deepnote_cell_height": 63,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temas a tratar\n",
        "\n",
        "- Codificaci√≥n de texto usando Bag of Words.\n",
        "- B√∫squeda del modelo √≥ptimo de clasificaci√≥n usando `GridSearch`\n",
        "- Uso de pipelines.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Asistencia **obligatoria** a instrucciones del lab (viernes 16.15). Luego, pueden quedarse trabajando en las salas o irse.\n",
        "- **No se revisar√°n entregas de personas ausentes**.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer material del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Obtener caracteristicas a partir de texto usando `CountVectorizer`.\n",
        "- Fijar un pipeline con un modelo base que luego se ir√° optimizando.\n",
        "- Comprender como realizar una b√∫squeda de grilla sobre un conjunto de clasificadores e hiperpar√°metros usando `GridSearch`.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
      ],
      "metadata": {
        "id": "6uBLPj1PzAHs",
        "cell_id": "29929e237c7e4bd58e32e7014be15f5d",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importamos librerias utiles üò∏"
      ],
      "metadata": {
        "id": "MhISwri4zAHy",
        "cell_id": "f5ade8a9983a447fb8a70a3f15daee03",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Librer√≠a Core del lab.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Pre-procesamiento\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Clasifaci√≥n\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Metricas de evaluaci√≥n\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Librer√≠a para plotear\n",
        "!pip install --upgrade plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Proyecciones en baja dimensionalidad: UMAP\n",
        "!pip install umap-learn\n",
        "\n",
        "# Librer√≠a para NLP\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "uyc33dKdzAHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cell_id": "6b4998dbdd2b486f9a27fc4040ca9c26",
        "outputId": "a9f4db7c-4d4e-4f3d-d5f4-b2c9c49b4c90",
        "ExecuteTime": {
          "end_time": "2021-03-29T00:08:16.884674Z",
          "start_time": "2021-03-29T00:08:16.349846Z"
        },
        "source_hash": "7ce9748b",
        "execution_start": 1637348694866,
        "execution_millis": 36497,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.13.1)\n",
            "Collecting plotly\n",
            "  Downloading plotly-5.15.0-py2.py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.1)\n",
            "Installing collected packages: plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.13.1\n",
            "    Uninstalling plotly-5.13.1:\n",
            "      Successfully uninstalled plotly-5.13.1\n",
            "Successfully installed plotly-5.15.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (67.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=069d6fe245a7d18e83638511b9b916780bfdb35752a764d202daa26280811d70\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=ce3a6607772de1a7d4a5ca65e4514b6e167e4941838af07e04afead3da73de94\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.10 umap-learn-0.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ¬øQuien es Bat Cow?"
      ],
      "metadata": {
        "id": "xpOTbQcxbSiy",
        "cell_id": "17fd1c4a7c1045a685dff360277240e7",
        "deepnote_cell_height": 82,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.imgur.com/D9f1RHy.jpg\" width=\"350\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "3Q93vbNS25bM",
        "cell_id": "49b52b8931f04a2fa4287082eb3da154",
        "deepnote_cell_height": 347.8125,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En vez de estar desarrollando las evaluaciones correspondientes a su curso, su profesor de catedra y su auxiliar discuten acerca la alineaci√≥n (h√©roe o villano) del personaje de ficci√≥n Bat-Cow.\n",
        "\n",
        "El cuerpo docente, no logra ponerse de acuerdo si el personaje es bueno, neutral o malo: el auxiliar plantea que Bat-cow posee una siniestra mirada, intrigante pero com√∫n caracter√≠stica de los personajes malvados.\n",
        "Por otra parte, extendiendo las ideas de Rousseau, el profesor plantea que tal como los humanos no nacen malos, no existe motivo por el cual una vaca con superpoderes deba serlo.\n",
        "\n",
        "Sin embargo, ambos concuerdan que es dif√≠cil estimar la alineaci√≥n solo usando los atributos f√≠sicos, por lo que creen el an√°lisis debe ser complementado a√∫n m√°s antes de comunicarle los resultados a su estudiantado. Buscando m√°s informaci√≥n, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineaci√≥n: la historia personal de cada superh√©roe o villano.\n",
        "\n",
        "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineaci√≥n de cada personaje basado en su historia personal.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servir√° para entrenar un modelo de clasificaci√≥n, mientras que el segundo es un dataset con personajes de ficci√≥n no etiquetados a predecir (s√≠, aqu√≠ est√° la misteriosa Batcow).\n",
        "\n",
        "Para comenzar cargue los dataset se√±alados y visualice a trav√©s de un head los atributos que poseen cada uno de los dataset.\n"
      ],
      "metadata": {
        "id": "jnmZfFpxTTYX",
        "cell_id": "98dbaf188dec4147b2b7e981fc64c61f",
        "deepnote_cell_height": 503.03125,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Si usted est√° utilizando Colaboratory le puede ser √∫til este c√≥digo para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = '/content/drive/MyDrive/lab_progra/'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ],
      "metadata": {
        "id": "Jqq-s010Iwl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cell_id": "82557a3ea7744f42a77dc7f5d97629ab",
        "outputId": "48d6d275-b8bf-458d-d197-06937db22db7",
        "source_hash": "c60dc4a7",
        "execution_start": 1637348657022,
        "execution_millis": 27,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "df_comics = pd.read_csv(path+'df_comics.csv')\n",
        "df_comics_no_label = pd.read_csv(path+'comics_no_label.csv')\n",
        "df_comics = df_comics.dropna(subset=['history_text']) # eliminar ejemplos sin historia"
      ],
      "metadata": {
        "id": "bED3w3tDbSCf",
        "cell_id": "c4b057f299d348fa839ac3c555241045",
        "source_hash": "443d6e8",
        "execution_start": 1637348732856,
        "execution_millis": 325,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# queda a labor de su equipo hacer el an√°lisis exploratorio\n",
        "df_comics.head()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "4c6367f4379042cc8515e0e86849acf3",
        "source_hash": "b986316d",
        "execution_start": 1637348731943,
        "execution_millis": 654,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "xYeRK_Se4PP3",
        "outputId": "d5d21096-4432-4d06-d4a1-fd51bbecc1f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0          name               real_name               full_name  \\\n",
              "0           0       3-D Man     Delroy Garrett, Jr.     Delroy Garrett, Jr.   \n",
              "1           2        A-Bomb  Richard Milhouse Jones  Richard Milhouse Jones   \n",
              "2           3            Aa                      Aa                     NaN   \n",
              "3           4    Aaron Cash              Aaron Cash              Aaron Cash   \n",
              "4           5  Aayla Secura            Aayla Secura                     NaN   \n",
              "\n",
              "  overall_score                                       history_text  \\\n",
              "0             6  Delroy Garrett, Jr. grew up to become a track ...   \n",
              "1            20   Richard \"Rick\" Jones was orphaned at a young ...   \n",
              "2            12  Aa is one of the more passive members of the P...   \n",
              "3             5  Aaron Cash is the head of security at Arkham A...   \n",
              "4             8  ayla Secura was a Rutian Twi'lek Jedi Knight (...   \n",
              "\n",
              "                                         powers_text  intelligence_score  \\\n",
              "0                                                NaN                  85   \n",
              "1    On rare occasions, and through unusual circu...                  80   \n",
              "2                                                NaN                  80   \n",
              "3                                                NaN                  80   \n",
              "4                                                NaN                  90   \n",
              "\n",
              "   strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
              "0              30           60  ...         0.0                      0.0   \n",
              "1             100           80  ...         0.0                      1.0   \n",
              "2              50           55  ...         0.0                      0.0   \n",
              "3              10           25  ...         0.0                      0.0   \n",
              "4              40           45  ...         0.0                      1.0   \n",
              "\n",
              "   has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
              "0                 0.0              0.0          0.0             1.0   \n",
              "1                 0.0              0.0          1.0             1.0   \n",
              "2                 0.0              0.0          0.0             0.0   \n",
              "3                 1.0              0.0          0.0             0.0   \n",
              "4                 0.0              0.0          0.0             0.0   \n",
              "\n",
              "  has_durability has_stamina has_agility has_super_strength  \n",
              "0            0.0         0.0         0.0                1.0  \n",
              "1            1.0         1.0         1.0                1.0  \n",
              "2            0.0         0.0         0.0                0.0  \n",
              "3            0.0         0.0         0.0                0.0  \n",
              "4            0.0         0.0         1.0                0.0  \n",
              "\n",
              "[5 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f07de52e-3e80-4d53-864a-d65fc11fe360\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>real_name</th>\n",
              "      <th>full_name</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>history_text</th>\n",
              "      <th>powers_text</th>\n",
              "      <th>intelligence_score</th>\n",
              "      <th>strength_score</th>\n",
              "      <th>speed_score</th>\n",
              "      <th>...</th>\n",
              "      <th>has_flight</th>\n",
              "      <th>has_accelerated_healing</th>\n",
              "      <th>has_weapons_master</th>\n",
              "      <th>has_intelligence</th>\n",
              "      <th>has_reflexes</th>\n",
              "      <th>has_super_speed</th>\n",
              "      <th>has_durability</th>\n",
              "      <th>has_stamina</th>\n",
              "      <th>has_agility</th>\n",
              "      <th>has_super_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3-D Man</td>\n",
              "      <td>Delroy Garrett, Jr.</td>\n",
              "      <td>Delroy Garrett, Jr.</td>\n",
              "      <td>6</td>\n",
              "      <td>Delroy Garrett, Jr. grew up to become a track ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85</td>\n",
              "      <td>30</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A-Bomb</td>\n",
              "      <td>Richard Milhouse Jones</td>\n",
              "      <td>Richard Milhouse Jones</td>\n",
              "      <td>20</td>\n",
              "      <td>Richard \"Rick\" Jones was orphaned at a young ...</td>\n",
              "      <td>On rare occasions, and through unusual circu...</td>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Aa</td>\n",
              "      <td>Aa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>Aa is one of the more passive members of the P...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>50</td>\n",
              "      <td>55</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>5</td>\n",
              "      <td>Aaron Cash is the head of security at Arkham A...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Aayla Secura</td>\n",
              "      <td>Aayla Secura</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>ayla Secura was a Rutian Twi'lek Jedi Knight (...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 82 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f07de52e-3e80-4d53-864a-d65fc11fe360')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f07de52e-3e80-4d53-864a-d65fc11fe360 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f07de52e-3e80-4d53-864a-d65fc11fe360');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "df_comics.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA1FPVbmbWfY",
        "outputId": "cd63c267-3f43-4f8d-828c-28cc738cb25b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1285, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comics_no_label.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "-58xdKBp7RFx",
        "outputId": "82a429bb-5dbd-4ac0-a59d-b182d29517c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0              name    real_name        full_name overall_score  \\\n",
              "0           1     514A (Gotham)  Bruce Wayne              NaN            10   \n",
              "1          14        Ace Morgan  Kyle Morgan              NaN             7   \n",
              "2          17             A'dal          NaN              NaN             7   \n",
              "3          27  Agent Zero (FOX)  David North              NaN             6   \n",
              "4          31        Ajax (FOX)      Francis  Francis Freeman             7   \n",
              "\n",
              "                                        history_text  \\\n",
              "0  He was one of the many prisoners of Indian Hil...   \n",
              "1                                                NaN   \n",
              "2  As with most of the naaru, little is known of ...   \n",
              "3  During mid-late 1973, Zero was a member of Tea...   \n",
              "4  Ajax (born Francis Freeman) was a human who ga...   \n",
              "\n",
              "                                         powers_text  intelligence_score  \\\n",
              "0                                                NaN                 100   \n",
              "1  Aviation:  Ace is an extremely skilled pilot, ...                  85   \n",
              "2                                                NaN                  85   \n",
              "3  Zero can absorb kinetic energy to further incr...                  90   \n",
              "4  Ajax has claimed that the procedure to obtain ...                  85   \n",
              "\n",
              "   strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
              "0              20           30  ...         0.0                      0.0   \n",
              "1              20           65  ...         0.0                      0.0   \n",
              "2              30           70  ...         0.0                      0.0   \n",
              "3              10           25  ...         0.0                      0.0   \n",
              "4              25           45  ...         0.0                      0.0   \n",
              "\n",
              "   has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
              "0                 0.0              0.0          1.0             0.0   \n",
              "1                 1.0              1.0          1.0             0.0   \n",
              "2                 0.0              0.0          0.0             0.0   \n",
              "3                 0.0              0.0          1.0             0.0   \n",
              "4                 1.0              1.0          1.0             0.0   \n",
              "\n",
              "  has_durability has_stamina has_agility  has_super_strength  \n",
              "0            1.0         0.0         0.0                 1.0  \n",
              "1            0.0         1.0         1.0                 0.0  \n",
              "2            0.0         0.0         0.0                 0.0  \n",
              "3            0.0         0.0         1.0                 0.0  \n",
              "4            1.0         0.0         0.0                 1.0  \n",
              "\n",
              "[5 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab0c3d98-bbb9-4380-a35c-2886650698ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>real_name</th>\n",
              "      <th>full_name</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>history_text</th>\n",
              "      <th>powers_text</th>\n",
              "      <th>intelligence_score</th>\n",
              "      <th>strength_score</th>\n",
              "      <th>speed_score</th>\n",
              "      <th>...</th>\n",
              "      <th>has_flight</th>\n",
              "      <th>has_accelerated_healing</th>\n",
              "      <th>has_weapons_master</th>\n",
              "      <th>has_intelligence</th>\n",
              "      <th>has_reflexes</th>\n",
              "      <th>has_super_speed</th>\n",
              "      <th>has_durability</th>\n",
              "      <th>has_stamina</th>\n",
              "      <th>has_agility</th>\n",
              "      <th>has_super_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>514A (Gotham)</td>\n",
              "      <td>Bruce Wayne</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>He was one of the many prisoners of Indian Hil...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>20</td>\n",
              "      <td>30</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>Ace Morgan</td>\n",
              "      <td>Kyle Morgan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aviation:  Ace is an extremely skilled pilot, ...</td>\n",
              "      <td>85</td>\n",
              "      <td>20</td>\n",
              "      <td>65</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>A'dal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>As with most of the naaru, little is known of ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85</td>\n",
              "      <td>30</td>\n",
              "      <td>70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>Agent Zero (FOX)</td>\n",
              "      <td>David North</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>During mid-late 1973, Zero was a member of Tea...</td>\n",
              "      <td>Zero can absorb kinetic energy to further incr...</td>\n",
              "      <td>90</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>Ajax (FOX)</td>\n",
              "      <td>Francis</td>\n",
              "      <td>Francis Freeman</td>\n",
              "      <td>7</td>\n",
              "      <td>Ajax (born Francis Freeman) was a human who ga...</td>\n",
              "      <td>Ajax has claimed that the procedure to obtain ...</td>\n",
              "      <td>85</td>\n",
              "      <td>25</td>\n",
              "      <td>45</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 82 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab0c3d98-bbb9-4380-a35c-2886650698ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab0c3d98-bbb9-4380-a35c-2886650698ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab0c3d98-bbb9-4380-a35c-2886650698ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comics.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju0HnoNs8Fqe",
        "outputId": "da4f51cf-593b-4a47-d5b2-874a68422a37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'name', 'real_name', 'full_name', 'overall_score',\n",
              "       'history_text', 'powers_text', 'intelligence_score', 'strength_score',\n",
              "       'speed_score', 'durability_score', 'power_score', 'combat_score',\n",
              "       'superpowers', 'alter_egos', 'aliases', 'place_of_birth',\n",
              "       'first_appearance', 'creator', 'alignment', 'occupation', 'base',\n",
              "       'teams', 'relatives', 'gender', 'type_race', 'height', 'weight',\n",
              "       'eye_color', 'hair_color', 'skin_color', 'img', 'has_electrokinesis',\n",
              "       'has_energy_constructs', 'has_mind_control_resistance',\n",
              "       'has_matter_manipulation', 'has_telepathy_resistance',\n",
              "       'has_mind_control', 'has_enhanced_hearing', 'has_dimensional_travel',\n",
              "       'has_element_control', 'has_size_changing', 'has_fire_resistance',\n",
              "       'has_fire_control', 'has_dexterity', 'has_reality_warping',\n",
              "       'has_illusions', 'has_energy_beams', 'has_peak_human_condition',\n",
              "       'has_shapeshifting', 'has_heat_resistance', 'has_jump',\n",
              "       'has_self-sustenance', 'has_energy_absorption', 'has_cold_resistance',\n",
              "       'has_magic', 'has_telekinesis', 'has_toxin_and_disease_resistance',\n",
              "       'has_telepathy', 'has_regeneration', 'has_immortality',\n",
              "       'has_teleportation', 'has_force_fields', 'has_energy_manipulation',\n",
              "       'has_endurance', 'has_longevity', 'has_weapon-based_powers',\n",
              "       'has_energy_blasts', 'has_enhanced_senses', 'has_invulnerability',\n",
              "       'has_stealth', 'has_marksmanship', 'has_flight',\n",
              "       'has_accelerated_healing', 'has_weapons_master', 'has_intelligence',\n",
              "       'has_reflexes', 'has_super_speed', 'has_durability', 'has_stamina',\n",
              "       'has_agility', 'has_super_strength'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comics['alignment']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuoMN3nB7vvA",
        "outputId": "b9822c3e-707c-4bd5-d8cd-3c85c8c10d7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Good\n",
              "1       Good\n",
              "2       Good\n",
              "3       Good\n",
              "4       Good\n",
              "        ... \n",
              "1362    Good\n",
              "1363    Good\n",
              "1364     Bad\n",
              "1365     Bad\n",
              "1366     Bad\n",
              "Name: alignment, Length: 1285, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comics_no_label['alignment']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkrulLPs76ok",
        "outputId": "95031592-57cb-488d-d2cf-9a724709542a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    NaN\n",
              "1    NaN\n",
              "2    NaN\n",
              "3    NaN\n",
              "4    NaN\n",
              "      ..\n",
              "79   NaN\n",
              "80   NaN\n",
              "81   NaN\n",
              "82   NaN\n",
              "83   NaN\n",
              "Name: alignment, Length: 84, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efectivamente, la columna a predecir es `alignment`"
      ],
      "metadata": {
        "id": "wYAaoZHz79eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Obtenci√≥n de Features y Bag of Words\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "i4tFPrFA4_O5",
        "cell_id": "2b5684743aec4d388edaa8f190652e9e",
        "deepnote_cell_height": 410,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero que todo, deben obtener un vector de caracter√≠sticas del atributo `history_text`, utilizando `Bag of Words`. En este atributo se presenta una breve descripci√≥n de la historia de cada uno de los personajes de ficci√≥n presentes en el dataset.\n",
        "\n",
        "Pero... antes de empezar, ¬øQue es `Bag of Words`?...\n",
        "\n",
        "`Bag of Words` es un modelo de conteo utilizado en Procesamiento de Lenguaje Natural (NLP) que tiene como objetivo generar una representaci√≥n vectorial (vector de caracter√≠sticas en nuestro cas) para cada documento a trav√©s del conteo de las palabras que contienen.\n",
        "\n",
        "La siguiente figura muestra un ejemplo de `Bag of Words` en acci√≥n:\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user.oc-static.com/upload/2020/10/23/16034397439042_surfin%20bird%20bow.png\" width=\"500\">\n",
        "</p>\n",
        "\n",
        "Como pueden ver, el modelo de `Bag of Words` no resulta tan complicado, ¬øpero c√≥mo lo aplicamos en python?.\n",
        "\n",
        "Como podr√°n darse cuenta del ejemplo anterior, para facilitar el conteo ser√° necesario transformar cada uno de los documentos en vectores, donde cada una de las posiciones posee un car√°cter. Este proceso es conocido como **tokenizaci√≥n** y lo podemos realizar de la siguiente forma:"
      ],
      "metadata": {
        "id": "f_4NF0_V5XZ-",
        "cell_id": "39e5b3d761274681bdafab029d6ede31",
        "deepnote_cell_height": 561.859375,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['The teacher rocks like a good rock & roll',\n",
        "             'the rock is the best actor in the world']\n",
        "\n",
        "nltk.download('punkt')\n",
        "docs_tokenizados = [word_tokenize(doc)  for doc in docs]\n",
        "docs_tokenizados"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "4225703f5ca94caeba76b5271167c8ec",
        "source_hash": "57e4888a",
        "execution_start": 1637346921830,
        "execution_millis": 8,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imdjPu584PP5",
        "outputId": "2c069995-4181-4296-a272-cccc7672a44e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
              " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos mejorar un poco m√°s el proceso de tokenizaci√≥n agregando\n",
        "\n",
        "- Stemming:  Definimos Stemming como un algoritmo basado en reglas que transforma las palabras a una forma general. Un ejemplo de stemming, es el siguiente:\n",
        "- Eliminaci√≥n de Stopwords: Eliminaci√≥n de palabras muy frecuentes que entorpecen la clasificaci√≥n (por ejemplo, el, la los, la, etc...)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://devopedia.org/images/article/218/8583.1569386710.png\" width=\"300\">\n",
        "</p>\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "38363e52900d4138aa13cfc88bb699dc",
        "deepnote_cell_height": 424.125,
        "deepnote_cell_type": "markdown",
        "id": "A3ZyWsbY4PP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos algunas stopword que queremos que sean eliminadas\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Definimos un tokenizador con Stemming\n",
        "class StemmerTokenizer:\n",
        "    def __init__(self):\n",
        "        self.ps = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        doc_tok = word_tokenize(doc)\n",
        "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
        "        return [self.ps.stem(t) for t in doc_tok]\n",
        "\n",
        "# Inicializamos tokenizador\n",
        "tokenizador = StemmerTokenizer()\n",
        "\n",
        "# Creamos algunos documentos\n",
        "docs = ['The teacher rocks like a good rock & roll',\n",
        "        'the rock is the best actor in the world',\n",
        "        'New York is a beautiful city']\n",
        "\n",
        "# Obtenemos el token del primer documento\n",
        "[tokenizador(doc) for doc in docs]"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "281adedd8d3e4785931934eadd57abfb",
        "source_hash": "d7f59237",
        "execution_start": 1637346924545,
        "execution_millis": 36,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR6tjlr74PP6",
        "outputId": "640fea77-20d1-4fe2-ed7f-446ad37651dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'teacher', 'rock', 'like', 'good', 'rock', '&', 'roll'],\n",
              " ['rock', 'best', 'actor', 'world'],\n",
              " ['new', 'york', 'beauti', 'citi']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparaci√≥n con el caso anterior\n",
        "docs_tokenizados = [word_tokenize(doc) for doc in docs]\n",
        "docs_tokenizados"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "3d0f1a2529964cedb72ccc62a8e818a5",
        "source_hash": "2503a9b4",
        "execution_start": 1637346927213,
        "execution_millis": 13,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDWfXbGB4PP8",
        "outputId": "7f08e21a-78f0-435f-fce4-481cfa124994"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
              " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n",
              " ['New', 'York', 'is', 'a', 'beautiful', 'city']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Al Estilo Scikit\n",
        "\n",
        "Scikit implementa `bag of words` a trav√©s de la clase `CountVectorizer()` la cual contiene muchas opciones para mejorar la tokenizaci√≥n."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "937e18f6c6a747f7893b43a25d6aa65c",
        "deepnote_cell_height": 110.78125,
        "deepnote_cell_type": "markdown",
        "id": "_bk6C4QE4PP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow = CountVectorizer(tokenizer= StemmerTokenizer())\n",
        "df = bow.fit_transform(docs)\n",
        "\n",
        "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "c898d0dca5bd47cd80f4a8566cf5cc13",
        "source_hash": "2bc7124d",
        "execution_start": 1637346927803,
        "execution_millis": 152,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "rwpYiIhg4PP-",
        "outputId": "20dc2ae8-f356-461e-d56e-3fd3bf715642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   &  actor  beauti  best  citi  good  like  new  rock  roll  teacher  world  \\\n",
              "0  1      0       0     0     0     1     1    0     2     1        1      0   \n",
              "1  0      1       0     1     0     0     0    0     1     0        0      1   \n",
              "2  0      0       1     0     1     0     0    1     0     0        0      0   \n",
              "\n",
              "   york  \n",
              "0     0  \n",
              "1     0  \n",
              "2     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6671ad4e-8f02-4e7d-9809-311cb49be483\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>actor</th>\n",
              "      <th>beauti</th>\n",
              "      <th>best</th>\n",
              "      <th>citi</th>\n",
              "      <th>good</th>\n",
              "      <th>like</th>\n",
              "      <th>new</th>\n",
              "      <th>rock</th>\n",
              "      <th>roll</th>\n",
              "      <th>teacher</th>\n",
              "      <th>world</th>\n",
              "      <th>york</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6671ad4e-8f02-4e7d-9809-311cb49be483')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6671ad4e-8f02-4e7d-9809-311cb49be483 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6671ad4e-8f02-4e7d-9809-311cb49be483');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las cosas m√°s interesantes que provee son el use de n-gramas, los cuales, en palabras simples, son conjuntos de n-palabras que se concatenan entre si y que se consideran como tokens separados.\n",
        "\n",
        "Pensemos en `Nueva York`. Cuando se tokeniza Nueva York, se generan dos tokens independientes que a simple vista no tienen relaci√≥n: `Nueva` `York`.\n",
        "Al usar n-gramas (en un rango min=1,max=2) , generamos tanto `Nueva` y `York` como tambi√©n `Nueva York` como un token independiente."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d9184cbee66a498bbe0050076342f306",
        "deepnote_cell_height": 155.953125,
        "deepnote_cell_type": "markdown",
        "id": "_r5GnJW64PP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2))\n",
        "df = bow.fit_transform(docs)\n",
        "\n",
        "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "8aa91d98ce4d4fd1b336e730702a9832",
        "source_hash": "6af25c7e",
        "execution_start": 1637346930092,
        "execution_millis": 241,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "m2QkwKiN4PP_",
        "outputId": "1de84aec-e0b8-4f36-962d-4ec3968ad56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   &  & roll  actor  actor world  beauti  beauti citi  best  best actor  citi  \\\n",
              "0  1       1      0            0       0            0     0           0     0   \n",
              "1  0       0      1            1       0            0     1           1     0   \n",
              "2  0       0      0            0       1            1     0           0     1   \n",
              "\n",
              "   good  ...  rock  rock &  rock best  rock like  roll  teacher  teacher rock  \\\n",
              "0     1  ...     2       1          0          1     1        1             1   \n",
              "1     0  ...     1       0          1          0     0        0             0   \n",
              "2     0  ...     0       0          0          0     0        0             0   \n",
              "\n",
              "   world  york  york beauti  \n",
              "0      0     0            0  \n",
              "1      1     0            0  \n",
              "2      0     1            1  \n",
              "\n",
              "[3 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8b1834f-d880-42c9-ad47-6750b25d6e38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>&amp; roll</th>\n",
              "      <th>actor</th>\n",
              "      <th>actor world</th>\n",
              "      <th>beauti</th>\n",
              "      <th>beauti citi</th>\n",
              "      <th>best</th>\n",
              "      <th>best actor</th>\n",
              "      <th>citi</th>\n",
              "      <th>good</th>\n",
              "      <th>...</th>\n",
              "      <th>rock</th>\n",
              "      <th>rock &amp;</th>\n",
              "      <th>rock best</th>\n",
              "      <th>rock like</th>\n",
              "      <th>roll</th>\n",
              "      <th>teacher</th>\n",
              "      <th>teacher rock</th>\n",
              "      <th>world</th>\n",
              "      <th>york</th>\n",
              "      <th>york beauti</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows √ó 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8b1834f-d880-42c9-ad47-6750b25d6e38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8b1834f-d880-42c9-ad47-6750b25d6e38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8b1834f-d880-42c9-ad47-6750b25d6e38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "De los resultados, podemos ver que generamos vectores de conteo para cada una de las palabras que conforman el corpus.  Un punto extra que se agrega en esta obtenci√≥n de frecuencias son los bigramas, que b√°sicamente son el conjunto de palabras de tama√±o de aparecen juntas en el texto."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "81f6a40097954939a7854adbbe28fdc6",
        "deepnote_cell_height": 97.171875,
        "deepnote_cell_type": "markdown",
        "id": "ks9iNqk64PP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codificando los Super{heroes, villanos}  [0.5 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://c.tenor.com/LkQzw7k5DV4AAAAd/anime-hacking.gif\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "Conociendo ahora que es el proceso de `bag of words`, aplique este modelo de obtenci√≥n de caracteristicas de la siguiente forma en un pipeline:\n",
        "\n",
        "- Utilice el tokenizador entregado.\n",
        "- Obtenga caracteristicas de los unigramas y bigramas del texto (tal como el ejemplo).\n",
        "\n",
        "```python\n",
        "bog = CountVectorizer(tokenizer= StemmerTokenizer(),`\n",
        "                      ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
        "                      )\n",
        "```"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "07780e17fbf349afaba37a0aef11e2f1",
        "deepnote_cell_height": 547,
        "deepnote_cell_type": "markdown",
        "id": "-mMe1b6l4PQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
        "\n",
        "```python\n",
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "```\n",
        "\n",
        "No es necesario que obtenga un dataframe en concreto con las caracter√≠sticas solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
        "\n",
        "**To-Do:**\n",
        "- [X] Obtener a traves de Bag of Words (`CountVectorizer`) caracteristicas del resumen de historia de cada personaje.\n",
        "- [X] Aplicar `MinMaxScaler` sobre los atributos de interes."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "58abb21ee53c424a96ca09d3c3f91d51",
        "deepnote_cell_height": 332.90625,
        "deepnote_cell_type": "markdown",
        "id": "B3k0PP3E4PQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta:**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "a33d10178fa84f7f8834eeaddf78f4c4",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "19MiCK5a4PQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "text = 'history_text'"
      ],
      "metadata": {
        "id": "JArkQ45bdUTf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaller\n",
        "minmax = MinMaxScaler()\n",
        "#BagOfWords\n",
        "bow = CountVectorizer(tokenizer = StemmerTokenizer(),\n",
        "                      ngram_range=(1,2)\n",
        "                      )"
      ],
      "metadata": {
        "id": "ykZSHvr0iKw7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepro\n",
        "preprocesador = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('BoW', bow, text),\n",
        "        ('MinMax', minmax, atributos_de_interes),\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    sparse_threshold=0\n",
        "    )"
      ],
      "metadata": {
        "id": "pHw6zxCZiB8Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('prepro', preprocesador),\n",
        "])"
      ],
      "metadata": {
        "id": "ay080DunHcOS",
        "cell_id": "20d7a7fe8e024e408b2016a1e4d6deef",
        "deepnote_cell_height": 66,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Dise√±o de Baseline y  Primer Entrenamiento  [1 Puntos]\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "stHncQ-A-j4I",
        "cell_id": "9df292283e4449b2a4b5d60dcf2987c0",
        "owner_user_id": "d50c3174-babb-4861-9c71-7e3af66458b8",
        "deepnote_cell_height": 317.5,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva secci√≥n\n",
        "Genere un Pipeline con las caracteristicas solicitadas en la secci√≥n 1.1, un selector de mejores features `SelectPercentile` con m√©trica `f_classif` y percentile=90 y un clasificador `MultinomialNB()` por defecto.\n",
        "\n",
        "Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde las etiquetas estar√° dado por el atributo `alignment`.\n",
        "\n",
        "Entrene el modelo y reporte el desempe√±o con un `classification_report`. ¬ø Nos recomendar√≠a predecir la alineaci√≥n de BatCow con este clasificador?.\n",
        "\n",
        "Finalmente, compare el modelo entrenado con un modelo Dummy estratificado y responda: ¬øEl clasificador entrenado es mejor que el dummy que entrega respuestas al azar?\n",
        "\n",
        "**To-do:**\n",
        "- [ ] Realizar un pipeline con las caracteristicas solicitadas en 1.1, ejecutar holdout y aplicar un clasificador `MultinomialNB()`.\n",
        "- [ ] Entrenar el pipeline, calcular el `classification_report` asociado y comentar los resultados.\n",
        "- [ ] Entrenar un `DummyClassifier` con estrategia `statified`, calcular el `classification_report` asociado y comentar que implican los scores obtenidos en comparaci√≥n con los resultados del baseline."
      ],
      "metadata": {
        "id": "NeMiptpQ_EWb",
        "cell_id": "0de6d1a9fc4d400f972e7d0511ce2cf3",
        "deepnote_cell_height": 455.859375,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_comics.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "CH2alglw50ic",
        "outputId": "eaa5855f-780a-4bb9-dc9e-2b2c5ddb5c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0          name               real_name               full_name  \\\n",
              "0           0       3-D Man     Delroy Garrett, Jr.     Delroy Garrett, Jr.   \n",
              "1           2        A-Bomb  Richard Milhouse Jones  Richard Milhouse Jones   \n",
              "2           3            Aa                      Aa                     NaN   \n",
              "3           4    Aaron Cash              Aaron Cash              Aaron Cash   \n",
              "4           5  Aayla Secura            Aayla Secura                     NaN   \n",
              "\n",
              "  overall_score                                       history_text  \\\n",
              "0             6  Delroy Garrett, Jr. grew up to become a track ...   \n",
              "1            20   Richard \"Rick\" Jones was orphaned at a young ...   \n",
              "2            12  Aa is one of the more passive members of the P...   \n",
              "3             5  Aaron Cash is the head of security at Arkham A...   \n",
              "4             8  ayla Secura was a Rutian Twi'lek Jedi Knight (...   \n",
              "\n",
              "                                         powers_text  intelligence_score  \\\n",
              "0                                                NaN                  85   \n",
              "1    On rare occasions, and through unusual circu...                  80   \n",
              "2                                                NaN                  80   \n",
              "3                                                NaN                  80   \n",
              "4                                                NaN                  90   \n",
              "\n",
              "   strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
              "0              30           60  ...         0.0                      0.0   \n",
              "1             100           80  ...         0.0                      1.0   \n",
              "2              50           55  ...         0.0                      0.0   \n",
              "3              10           25  ...         0.0                      0.0   \n",
              "4              40           45  ...         0.0                      1.0   \n",
              "\n",
              "   has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
              "0                 0.0              0.0          0.0             1.0   \n",
              "1                 0.0              0.0          1.0             1.0   \n",
              "2                 0.0              0.0          0.0             0.0   \n",
              "3                 1.0              0.0          0.0             0.0   \n",
              "4                 0.0              0.0          0.0             0.0   \n",
              "\n",
              "  has_durability has_stamina has_agility has_super_strength  \n",
              "0            0.0         0.0         0.0                1.0  \n",
              "1            1.0         1.0         1.0                1.0  \n",
              "2            0.0         0.0         0.0                0.0  \n",
              "3            0.0         0.0         0.0                0.0  \n",
              "4            0.0         0.0         1.0                0.0  \n",
              "\n",
              "[5 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53cca5e1-d590-4167-a993-9105c366f7d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>real_name</th>\n",
              "      <th>full_name</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>history_text</th>\n",
              "      <th>powers_text</th>\n",
              "      <th>intelligence_score</th>\n",
              "      <th>strength_score</th>\n",
              "      <th>speed_score</th>\n",
              "      <th>...</th>\n",
              "      <th>has_flight</th>\n",
              "      <th>has_accelerated_healing</th>\n",
              "      <th>has_weapons_master</th>\n",
              "      <th>has_intelligence</th>\n",
              "      <th>has_reflexes</th>\n",
              "      <th>has_super_speed</th>\n",
              "      <th>has_durability</th>\n",
              "      <th>has_stamina</th>\n",
              "      <th>has_agility</th>\n",
              "      <th>has_super_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3-D Man</td>\n",
              "      <td>Delroy Garrett, Jr.</td>\n",
              "      <td>Delroy Garrett, Jr.</td>\n",
              "      <td>6</td>\n",
              "      <td>Delroy Garrett, Jr. grew up to become a track ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85</td>\n",
              "      <td>30</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A-Bomb</td>\n",
              "      <td>Richard Milhouse Jones</td>\n",
              "      <td>Richard Milhouse Jones</td>\n",
              "      <td>20</td>\n",
              "      <td>Richard \"Rick\" Jones was orphaned at a young ...</td>\n",
              "      <td>On rare occasions, and through unusual circu...</td>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Aa</td>\n",
              "      <td>Aa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>Aa is one of the more passive members of the P...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>50</td>\n",
              "      <td>55</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>5</td>\n",
              "      <td>Aaron Cash is the head of security at Arkham A...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Aayla Secura</td>\n",
              "      <td>Aayla Secura</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>ayla Secura was a Rutian Twi'lek Jedi Knight (...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 82 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53cca5e1-d590-4167-a993-9105c366f7d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53cca5e1-d590-4167-a993-9105c366f7d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53cca5e1-d590-4167-a993-9105c366f7d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta:**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "81b793138ec14f3d92713dab4e6bebb9",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "XOiI-6Q74PQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Pipeline([\n",
        "    ('prepr', preprocesador),\n",
        "    ('seleccion', SelectPercentile(score_func=f_classif, percentile=90)),\n",
        "    ('clasificador', MultinomialNB())\n",
        "])\n",
        "\n",
        "X = df_comics.drop(['alignment', 'name',\t'real_name',\t'full_name', \t'powers_text'], axis=1)\n",
        "y = df_comics['alignment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=190423)"
      ],
      "metadata": {
        "id": "_hHpPDooPafy",
        "cell_id": "e68a1a925b9d429d93f7b3e888eb9c06",
        "deepnote_cell_height": 66,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R91Fx6Pn4ZA2",
        "outputId": "9ae9c414-a330-4052-ee6e-473e393008fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reportamos resultados\n",
        "report = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "j72FWGr84gws"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dummy\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "y_pred_dummy = dummy_clf.predict(X_test)\n",
        "dummy_report = classification_report(y_test, y_pred_dummy)"
      ],
      "metadata": {
        "id": "LzJdhXnA5AGg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbNwIvFe69NA",
        "outputId": "3b2d90ec-3863-4a11-88d3-b8054796f4af"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.80      0.10      0.18        77\n",
            "        Good       0.63      0.99      0.77       156\n",
            "     Neutral       1.00      0.04      0.08        24\n",
            "\n",
            "    accuracy                           0.64       257\n",
            "   macro avg       0.81      0.38      0.35       257\n",
            "weighted avg       0.72      0.64      0.53       257\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dummy_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13oEGqSt7A1Z",
        "outputId": "15ce7e9e-75e3-4272-8b3e-e8a3ad5e3084"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.30      0.42      0.35        77\n",
            "        Good       0.56      0.47      0.51       156\n",
            "     Neutral       0.05      0.04      0.05        24\n",
            "\n",
            "    accuracy                           0.41       257\n",
            "   macro avg       0.30      0.31      0.30       257\n",
            "weighted avg       0.43      0.41      0.42       257\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "¬ø Nos recomendar√≠a predecir la alineaci√≥n de BatCow con este clasificador?\n",
        "\n",
        "No, porque los resultados no son suficientemente alentadores para asegurarnos que las predicci√≥n ser√°n correctas en datos no etiquetados con anterioridad\n",
        "\n",
        "¬øEl clasificador entrenado es mejor que el dummy que entrega respuestas al azar?\n",
        "\n",
        "Para la clase malo es mejor, pero para el resto no. Esto nos puede ayudar a concluir que el BoW si entrega informaci√≥n relevante para etiquetar personajes.\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "f69a4b33bd9442fabbc34bcaf2c87581",
        "deepnote_cell_height": 70.796875,
        "deepnote_cell_type": "markdown",
        "id": "aekueO9C4PQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Busqueda del Mejor Modelo con Grid Search [4 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "pfm7I2B7_rfB",
        "cell_id": "efd50fb630984a12a0a56ced0c73e088",
        "deepnote_cell_height": 400,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No conformes con el rendimiento obtenido en la secci√≥n 1.2, el cuerpo docente les pide que realicen un **`HalvingGridSearchCV`** con diferentes par√°metros para mejorar el rendimiento de la clasificaci√≥n. Para esto, se le solicita que defina:\n",
        "\n",
        "- Tres clasificadores distintos en donde varie sus par√°metros. Considere usar modelos cl√°sicos como tambi√©n los basados en ensamblaje.\n",
        "- Modificar `n-gram` range del `CountVectorizer` probando `(1,1), (1,2) y (1,3)`. Examinar tambi√©n los otros par√°metros de CountVectorizer como por ejemplo `max_df`, `min_df`, etc... ([Documentaci√≥n aqu√≠](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html))\n",
        "- Seleccionar las columnas que contribuyen con la mayor informaci√≥n para la clasificaci√≥n con `SelectPercentile` en los percentiles `[20, 40, 60, 80]` (puede usar la m√©trica que usted quiera).\n",
        "- Reporte la mejor combinaci√≥n encontrada y justifique por qu√© cree que es la mejor seg√∫n el clasificador usado, la cantidad de columnas seleccionadas y los par√°metros de CountVectorizer seleccionados por GridSearch.\n",
        "\n",
        "A continuaci√≥n, un ejemplo de parametros para GridSearch para una b√∫squeda de 3 clasificadores distintos:\n",
        "\n",
        "```python\n",
        "params = [\n",
        "       # clasificador 1 + hiperpar√°metros\n",
        "       {'clf': classificator1(),\n",
        "        'clf__penalty': ['ovr'],\n",
        "       # clasificador 1 + hiperpar√°metros\n",
        "       {'clf': classificator2(),\n",
        "        'clf__n_estimators': [200]},\n",
        "       # clasificador 1 + hiperpar√°metros\n",
        "       {'clf': classificator3(),\n",
        "        ...\n",
        "       }\n",
        "       ]\n",
        "```\n",
        "\n",
        "**Nota 1**: Puede ver los par√°metros modificables aplicando el m√©todo get_params() sobre su pipeline. Ver la clase de GridSearch para mayor informaci√≥n sobre la sint√°xis de las grillas.\n",
        "\n",
        "**Nota 2**: Recuerde inicializar los clasificadores con un random state definido.\n",
        "\n",
        "**Nota 3**: Puede usar en `HalvingGridSearchCV` el par√°metro `verbose=10` para ver que GridSearch le indique el estado de su ejecuci√≥n.\n",
        "\n",
        "**Nota 3:** El GridSearch puede tomar tiempos de b√∫squeda exorbitantes, por lo que se le recomienda no agrandar mucho el espacio de b√∫squeda, dejar corriendo el c√≥digo y tomarse un tecito."
      ],
      "metadata": {
        "id": "14siiavzK67p",
        "cell_id": "69063d71deb042109162f3cb4199b231",
        "deepnote_cell_height": 859.5,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta:**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "7c9f3de702234ddca989bf2125fab779",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "2fjb87P94PQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Configuraciones de BoW ###\n",
        "bow1 = CountVectorizer(tokenizer = StemmerTokenizer(),\n",
        "                      ngram_range=(1,1),\n",
        "                      max_df=2\n",
        "                      )"
      ],
      "metadata": {
        "id": "9ApsjW_j-ZwT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "\n",
        "#### C√≥digo aqu√≠ ####\n",
        "\n",
        "### Modificaciones en la representaci√≥n del BoW + otras caracter√≠sticas ###\n",
        "preprocesador1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('BoW', bow1, text),\n",
        "        ('MinMax', minmax, atributos_de_interes),\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    sparse_threshold=0\n",
        "    )\n"
      ],
      "metadata": {
        "id": "oNvHOHELUoIv",
        "cell_id": "4663cec8ef58413cb9cf36044d5c8da2",
        "deepnote_cell_height": 66,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
        "from sklearn.model_selection import HalvingGridSearchCV"
      ],
      "metadata": {
        "id": "GoBy_gQQDJa3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "G3g_AlsuXI6j"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def train_and_evaluate(\n",
        "    pipe, print_=True, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test\n",
        "):\n",
        "\n",
        "    # notar que los datasets son par√°metros por defecto.\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    if print_:\n",
        "        print(\"Matriz de confusi√≥n: \\n\")\n",
        "        print(confusion_matrix(y_test, y_pred, labels=pipe.classes_))\n",
        "        print(\"\\nReporte de Clasificaci√≥n: \\n\")\n",
        "        print(\n",
        "            classification_report(y_test, y_pred, target_names=pipe.classes_),\n",
        "        )\n",
        "\n",
        "    return f1_score(y_test, y_pred, average=\"macro\")"
      ],
      "metadata": {
        "id": "Gt6vBCgiDVHh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Primer clasificador"
      ],
      "metadata": {
        "id": "0MD2w9LeDGkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "selection_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessing\", preprocesador1),\n",
        "        (\"selection\", SelectPercentile(f_classif, percentile=20)),\n",
        "        (\"model\", RandomForestClassifier()),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "E1XDfeitCDus"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        \"selection__percentile\": range(40, 60, 80),\n",
        "        \"model__criterion\": [\"gini\", \"entropy\"],\n",
        "        \"model__bootstrap\": [True, False],\n",
        "        \"preprocessing__BoW__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
        "        \"preprocessing__BoW__max_df\": [0,1,2],\n",
        "        \"preprocessing__BoW__min_df\": [0,1,2]\n",
        "    }\n",
        "]\n",
        "\n",
        "hgs = HalvingGridSearchCV(selection_pipeline, param_grid, n_jobs=-1, scoring='f1_macro', verbose=10)"
      ],
      "metadata": {
        "id": "pf5laEhV02pc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(hgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWEhtsTlXLhf",
        "outputId": "723936d5-e792-466a-b088-593c7ad79d96"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 5\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 30\n",
            "max_resources_: 1028\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 108\n",
            "n_resources: 30\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "240 fits failed out of a total of 540.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1401, in fit_transform\n",
            "    X, self.stop_words_ = self._limit_features(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1253, in _limit_features\n",
            "    raise ValueError(\n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1398, in fit_transform\n",
            "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
            "ValueError: max_df corresponds to < documents than min_df\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.23396825 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.21174603 0.21174603 0.24666667 0.21174603 0.21174603 0.24666667\n",
            " 0.30960317 0.25626984 0.25309524        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.22285714 0.24666667 0.24666667\n",
            " 0.21619048 0.21174603 0.24666667 0.28960317 0.3097619  0.27309524\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.21015873 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.26952381 0.21174603 0.22285714 0.19238095 0.22285714 0.21174603\n",
            " 0.27174603 0.25626984 0.25626984        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.23396825 0.24666667 0.24666667 0.23396825 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.24952381 0.21619048 0.22285714\n",
            " 0.26952381 0.22285714 0.24666667 0.26293651 0.30960317 0.30960317]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         0.99359268\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 36\n",
            "n_resources: 90\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.23396825 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.21174603 0.21174603 0.24666667 0.21174603 0.21174603 0.24666667\n",
            " 0.30960317 0.25626984 0.25309524        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.22285714 0.24666667 0.24666667\n",
            " 0.21619048 0.21174603 0.24666667 0.28960317 0.3097619  0.27309524\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.21015873 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.26952381 0.21174603 0.22285714 0.19238095 0.22285714 0.21174603\n",
            " 0.27174603 0.25626984 0.25626984        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.23396825 0.24666667 0.24666667 0.23396825 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.24952381 0.21619048 0.22285714\n",
            " 0.26952381 0.22285714 0.24666667 0.26293651 0.30960317 0.30960317\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.2692994  0.23464469\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469 0.29787803\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469\n",
            " 0.23464469 0.23464469 0.23464469 0.32088889 0.31224242 0.30345277\n",
            " 0.31052937 0.26826251 0.32398008 0.34445813 0.32857143 0.41416455\n",
            " 0.33564522 0.29089187 0.29813232 0.29888306 0.29623844 0.28045689]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         0.99359268\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345\n",
            " 1.         1.         1.         1.         1.         0.99574832\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.99793109 1.         1.         1.         1.         1.\n",
            " 0.99300043 0.99300043 1.         1.         0.99762963 0.99762963\n",
            " 0.99762963 0.99762963 0.99762963 1.         1.         0.99762963\n",
            " 0.99762963 0.99762963 0.99762963 0.99762963 0.99762963 0.99762963]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 2\n",
            "n_candidates: 12\n",
            "n_resources: 270\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.23396825 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.21174603 0.21174603 0.24666667 0.21174603 0.21174603 0.24666667\n",
            " 0.30960317 0.25626984 0.25309524        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.22285714 0.24666667 0.24666667\n",
            " 0.21619048 0.21174603 0.24666667 0.28960317 0.3097619  0.27309524\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.21015873 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.26952381 0.21174603 0.22285714 0.19238095 0.22285714 0.21174603\n",
            " 0.27174603 0.25626984 0.25626984        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.23396825 0.24666667 0.24666667 0.23396825 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.24952381 0.21619048 0.22285714\n",
            " 0.26952381 0.22285714 0.24666667 0.26293651 0.30960317 0.30960317\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.2692994  0.23464469\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469 0.29787803\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469\n",
            " 0.23464469 0.23464469 0.23464469 0.32088889 0.31224242 0.30345277\n",
            " 0.31052937 0.26826251 0.32398008 0.34445813 0.32857143 0.41416455\n",
            " 0.33564522 0.29089187 0.29813232 0.29888306 0.29623844 0.28045689\n",
            " 0.28717694 0.32567244 0.28836751 0.36464975 0.34500333 0.3157098\n",
            " 0.32318242 0.34607798 0.29802525 0.30423205 0.30436799 0.36849871]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         0.99359268\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345\n",
            " 1.         1.         1.         1.         1.         0.99574832\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.99793109 1.         1.         1.         1.         1.\n",
            " 0.99300043 0.99300043 1.         1.         0.99762963 0.99762963\n",
            " 0.99762963 0.99762963 0.99762963 1.         1.         0.99762963\n",
            " 0.99762963 0.99762963 0.99762963 0.99762963 0.99762963 0.99762963\n",
            " 1.         1.         0.99704695 1.         1.         1.\n",
            " 1.         0.99704695 1.         1.         1.         0.99704695]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 3\n",
            "n_candidates: 4\n",
            "n_resources: 810\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.23396825 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.21174603 0.21174603 0.24666667 0.21174603 0.21174603 0.24666667\n",
            " 0.30960317 0.25626984 0.25309524        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.22285714 0.24666667 0.24666667\n",
            " 0.21619048 0.21174603 0.24666667 0.28960317 0.3097619  0.27309524\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.21015873 0.24666667 0.24666667\n",
            " 0.23396825 0.24666667 0.24666667        nan        nan        nan\n",
            " 0.26952381 0.21174603 0.22285714 0.19238095 0.22285714 0.21174603\n",
            " 0.27174603 0.25626984 0.25626984        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.23396825 0.24666667 0.24666667 0.23396825 0.24666667 0.24666667\n",
            "        nan        nan        nan 0.24952381 0.21619048 0.22285714\n",
            " 0.26952381 0.22285714 0.24666667 0.26293651 0.30960317 0.30960317\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.2692994  0.23464469\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469 0.29787803\n",
            " 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469 0.23464469\n",
            " 0.23464469 0.23464469 0.23464469 0.32088889 0.31224242 0.30345277\n",
            " 0.31052937 0.26826251 0.32398008 0.34445813 0.32857143 0.41416455\n",
            " 0.33564522 0.29089187 0.29813232 0.29888306 0.29623844 0.28045689\n",
            " 0.28717694 0.32567244 0.28836751 0.36464975 0.34500333 0.3157098\n",
            " 0.32318242 0.34607798 0.29802525 0.30423205 0.30436799 0.36849871\n",
            " 0.33134689 0.36070828 0.33556614 0.35695075]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         0.99359268\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.96871345 0.96871345 0.96871345        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         0.96871345 0.96871345 0.96871345\n",
            " 1.         1.         1.         1.         1.         0.99574832\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.99793109 1.         1.         1.         1.         1.\n",
            " 0.99300043 0.99300043 1.         1.         0.99762963 0.99762963\n",
            " 0.99762963 0.99762963 0.99762963 1.         1.         0.99762963\n",
            " 0.99762963 0.99762963 0.99762963 0.99762963 0.99762963 0.99762963\n",
            " 1.         1.         0.99704695 1.         1.         1.\n",
            " 1.         0.99704695 1.         1.         1.         0.99704695\n",
            " 0.99904035 0.98971782 0.99928121 0.98971782]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusi√≥n: \n",
            "\n",
            "[[ 20  55   2]\n",
            " [ 33 119   4]\n",
            " [  8  15   1]]\n",
            "\n",
            "Reporte de Clasificaci√≥n: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.33      0.26      0.29        77\n",
            "        Good       0.63      0.76      0.69       156\n",
            "     Neutral       0.14      0.04      0.06        24\n",
            "\n",
            "    accuracy                           0.54       257\n",
            "   macro avg       0.37      0.35      0.35       257\n",
            "weighted avg       0.49      0.54      0.51       257\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34807542465326474"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgs.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-J1j24BB5g5",
        "outputId": "5c12973a-64d9-4cba-8cce-a1481f367392"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__bootstrap': False,\n",
              " 'model__criterion': 'entropy',\n",
              " 'preprocessing__BoW__max_df': 2,\n",
              " 'preprocessing__BoW__min_df': 2,\n",
              " 'preprocessing__BoW__ngram_range': (1, 1),\n",
              " 'selection__percentile': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segundo clasificador"
      ],
      "metadata": {
        "id": "FImltAjiDK36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selection_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessing\", preprocesador1),\n",
        "        (\"selection\", SelectPercentile(f_classif, percentile=20)),\n",
        "        (\"model\", LinearSVC(random_state=0, tol=1e-5)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "f1JhiLMGDM0v"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        \"selection__percentile\": range(40, 60, 80),\n",
        "        \"model__C\": [0.1,1, 10, 100],\n",
        "        \"preprocessing__BoW__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
        "        \"preprocessing__BoW__max_df\": [0,1,2],\n",
        "        \"preprocessing__BoW__min_df\": [0,1,2]\n",
        "    }\n",
        "]\n",
        "\n",
        "hgs1 = HalvingGridSearchCV(selection_pipeline, param_grid, n_jobs=-1, scoring='f1_macro', verbose=10)"
      ],
      "metadata": {
        "id": "ftnan5YcDU35"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(hgs1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DNf3fDtFBPF",
        "outputId": "46ecf581-dd07-4e64-cdfa-68cba2d0e6d7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 5\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 30\n",
            "max_resources_: 1028\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 108\n",
            "n_resources: 30\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "240 fits failed out of a total of 540.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1401, in fit_transform\n",
            "    X, self.stop_words_ = self._limit_features(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1253, in _limit_features\n",
            "    raise ValueError(\n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1398, in fit_transform\n",
            "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
            "ValueError: max_df corresponds to < documents than min_df\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.34087302 0.28902116 0.28902116        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.31230159 0.24140212 0.24140212\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.28134921 0.24140212 0.24140212        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.28134921 0.24140212 0.24140212]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.98464646 1.         1.\n",
            " 0.98464646 1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.95070433 0.97332085 0.97332085        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.        ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 36\n",
            "n_resources: 90\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.34087302 0.28902116 0.28902116        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.31230159 0.24140212 0.24140212\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.28134921 0.24140212 0.24140212        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.28134921 0.24140212 0.24140212\n",
            " 0.25449383 0.26097924 0.25123375 0.25226155 0.24260317 0.25226155\n",
            " 0.25123375 0.25226155 0.24856924 0.25222141 0.24260317 0.24908694\n",
            " 0.24629548 0.24539464 0.28627467 0.24539464 0.24908694 0.24629548\n",
            " 0.28627467 0.25222141 0.24260317 0.24856924 0.27584581 0.28516854\n",
            " 0.28189939 0.28189939 0.28516854 0.28516854 0.28516854 0.27584581\n",
            " 0.39169902 0.40190652 0.36153756 0.4271968  0.43124657 0.39138487]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.98464646 1.         1.\n",
            " 0.98464646 1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.95070433 0.97332085 0.97332085        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.99100177 0.99297321 0.99297321 1.         1.         1.\n",
            " 1.         1.         0.99297321 0.99100177 1.         1.\n",
            " 0.99100177 0.99297321 0.95121213 0.99297321 1.         0.99100177\n",
            " 0.95121213 0.99100177 1.         0.99297321 0.98666995 1.\n",
            " 1.         1.         1.         1.         1.         0.98666995\n",
            " 0.98063452 0.98068637 0.95446176 0.95446176 0.97169266 0.89465845]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 2\n",
            "n_candidates: 12\n",
            "n_resources: 270\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.34087302 0.28902116 0.28902116        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.31230159 0.24140212 0.24140212\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.28134921 0.24140212 0.24140212        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.28134921 0.24140212 0.24140212\n",
            " 0.25449383 0.26097924 0.25123375 0.25226155 0.24260317 0.25226155\n",
            " 0.25123375 0.25226155 0.24856924 0.25222141 0.24260317 0.24908694\n",
            " 0.24629548 0.24539464 0.28627467 0.24539464 0.24908694 0.24629548\n",
            " 0.28627467 0.25222141 0.24260317 0.24856924 0.27584581 0.28516854\n",
            " 0.28189939 0.28189939 0.28516854 0.28516854 0.28516854 0.27584581\n",
            " 0.39169902 0.40190652 0.36153756 0.4271968  0.43124657 0.39138487\n",
            " 0.324266   0.33851268 0.324266   0.33851268 0.32551183 0.32551183\n",
            " 0.37170759 0.33960911 0.38136097 0.38137305 0.37316156 0.35253619]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.98464646 1.         1.\n",
            " 0.98464646 1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.95070433 0.97332085 0.97332085        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.99100177 0.99297321 0.99297321 1.         1.         1.\n",
            " 1.         1.         0.99297321 0.99100177 1.         1.\n",
            " 0.99100177 0.99297321 0.95121213 0.99297321 1.         0.99100177\n",
            " 0.95121213 0.99100177 1.         0.99297321 0.98666995 1.\n",
            " 1.         1.         1.         1.         1.         0.98666995\n",
            " 0.98063452 0.98068637 0.95446176 0.95446176 0.97169266 0.89465845\n",
            " 0.99210228 0.98852961 0.99210228 0.98852961 0.92693537 0.92693537\n",
            " 0.9533774  0.87128706 0.9325696  0.9310482  0.95771825 0.92445223]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 3\n",
            "n_candidates: 4\n",
            "n_resources: 810\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.34087302 0.28902116 0.28902116        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.31230159 0.24140212 0.24140212\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26087302 0.26087302 0.26087302\n",
            " 0.26087302 0.26087302 0.26087302        nan        nan        nan\n",
            " 0.26642857 0.26087302 0.26087302 0.26642857 0.26087302 0.26087302\n",
            " 0.28134921 0.24140212 0.24140212        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302 0.26087302\n",
            "        nan        nan        nan 0.26642857 0.26087302 0.26087302\n",
            " 0.26642857 0.26087302 0.26087302 0.28134921 0.24140212 0.24140212\n",
            " 0.25449383 0.26097924 0.25123375 0.25226155 0.24260317 0.25226155\n",
            " 0.25123375 0.25226155 0.24856924 0.25222141 0.24260317 0.24908694\n",
            " 0.24629548 0.24539464 0.28627467 0.24539464 0.24908694 0.24629548\n",
            " 0.28627467 0.25222141 0.24260317 0.24856924 0.27584581 0.28516854\n",
            " 0.28189939 0.28189939 0.28516854 0.28516854 0.28516854 0.27584581\n",
            " 0.39169902 0.40190652 0.36153756 0.4271968  0.43124657 0.39138487\n",
            " 0.324266   0.33851268 0.324266   0.33851268 0.32551183 0.32551183\n",
            " 0.37170759 0.33960911 0.38136097 0.38137305 0.37316156 0.35253619\n",
            " 0.34715903 0.34781219 0.37980077 0.37780665]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.98464646 1.         1.\n",
            " 0.98464646 1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.95070433 0.97332085 0.97332085        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 0.99100177 0.99297321 0.99297321 1.         1.         1.\n",
            " 1.         1.         0.99297321 0.99100177 1.         1.\n",
            " 0.99100177 0.99297321 0.95121213 0.99297321 1.         0.99100177\n",
            " 0.95121213 0.99100177 1.         0.99297321 0.98666995 1.\n",
            " 1.         1.         1.         1.         1.         0.98666995\n",
            " 0.98063452 0.98068637 0.95446176 0.95446176 0.97169266 0.89465845\n",
            " 0.99210228 0.98852961 0.99210228 0.98852961 0.92693537 0.92693537\n",
            " 0.9533774  0.87128706 0.9325696  0.9310482  0.95771825 0.92445223\n",
            " 0.93179846 0.94204918 0.85931618 0.85478854]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusi√≥n: \n",
            "\n",
            "[[ 11  63   3]\n",
            " [ 21 128   7]\n",
            " [  3  19   2]]\n",
            "\n",
            "Reporte de Clasificaci√≥n: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.31      0.14      0.20        77\n",
            "        Good       0.61      0.82      0.70       156\n",
            "     Neutral       0.17      0.08      0.11        24\n",
            "\n",
            "    accuracy                           0.55       257\n",
            "   macro avg       0.36      0.35      0.34       257\n",
            "weighted avg       0.48      0.55      0.49       257\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3356644114840836"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgs1.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-svXl7wBN23l",
        "outputId": "2f47db98-9f27-4e6c-e9cd-e592385331b4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__C': 10,\n",
              " 'preprocessing__BoW__max_df': 2,\n",
              " 'preprocessing__BoW__min_df': 2,\n",
              " 'preprocessing__BoW__ngram_range': (1, 1),\n",
              " 'selection__percentile': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tercer clasificador"
      ],
      "metadata": {
        "id": "AtPY-vn9OMyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selection_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessing\", preprocesador1),\n",
        "        (\"selection\", SelectPercentile(f_classif, percentile=20)),\n",
        "        (\"model\", svm.SVC()),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "hIucomzNOR_f"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        \"selection__percentile\": range(40, 60, 80),\n",
        "        \"model__C\": [0.1,1, 10, 100],\n",
        "        \"preprocessing__BoW__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
        "        \"preprocessing__BoW__max_df\": [0,1,2],\n",
        "        \"preprocessing__BoW__min_df\": [0,1,2]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "hgs2 = HalvingGridSearchCV(selection_pipeline, param_grid, n_jobs=-1, scoring='f1_macro', verbose=10)"
      ],
      "metadata": {
        "id": "_kXQi1HtOXv3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(hgs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrFFgTpEOZwj",
        "outputId": "a2dafcdf-0da8-44c1-ad08-766be3c4a90d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 5\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 30\n",
            "max_resources_: 1028\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 108\n",
            "n_resources: 30\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "240 fits failed out of a total of 540.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1401, in fit_transform\n",
            "    X, self.stop_words_ = self._limit_features(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1253, in _limit_features\n",
            "    raise ValueError(\n",
            "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 401, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 359, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 727, in fit_transform\n",
            "    result = self._fit_transform(X, y, _fit_transform_one)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1398, in fit_transform\n",
            "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
            "ValueError: max_df corresponds to < documents than min_df\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            " 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.31428571 0.27619048 0.26904762 0.31428571 0.27619048 0.26904762\n",
            "        nan        nan        nan 0.27619048 0.26904762 0.26904762\n",
            " 0.27619048 0.26904762 0.26904762 0.25571429 0.26904762 0.26904762\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.28428571 0.27619048 0.27619048\n",
            " 0.28428571 0.27619048 0.27619048        nan        nan        nan\n",
            " 0.32238095 0.27619048 0.33571429 0.32238095 0.27619048 0.33571429\n",
            " 0.29301587 0.27619048 0.27619048        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.28428571 0.26285714 0.26285714 0.28428571 0.26285714 0.26285714\n",
            "        nan        nan        nan 0.25015873 0.32238095 0.32238095\n",
            " 0.25015873 0.32238095 0.32238095 0.26111111 0.21428571 0.21428571]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            " 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.63897108 0.69431379 0.72783903 0.63897108 0.69431379 0.72783903\n",
            "        nan        nan        nan 0.54644866 0.66390528 0.69130378\n",
            " 0.54644866 0.66390528 0.69130378 0.61454572 0.60805377 0.60805377\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.85459316 0.90108089 0.92078876\n",
            " 0.85459316 0.90108089 0.92078876        nan        nan        nan\n",
            " 0.85459316 0.90279078 0.91235628 0.85459316 0.90279078 0.91235628\n",
            " 0.89564032 0.94879403 0.94879403        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.98191231 1.         1.         0.98191231 1.         1.\n",
            "        nan        nan        nan 0.97355286 1.         1.\n",
            " 0.97355286 1.         1.         0.98505231 0.99164054 0.99164054]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 1\n",
            "n_candidates: 36\n",
            "n_resources: 90\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            " 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.31428571 0.27619048 0.26904762 0.31428571 0.27619048 0.26904762\n",
            "        nan        nan        nan 0.27619048 0.26904762 0.26904762\n",
            " 0.27619048 0.26904762 0.26904762 0.25571429 0.26904762 0.26904762\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.28428571 0.27619048 0.27619048\n",
            " 0.28428571 0.27619048 0.27619048        nan        nan        nan\n",
            " 0.32238095 0.27619048 0.33571429 0.32238095 0.27619048 0.33571429\n",
            " 0.29301587 0.27619048 0.27619048        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.28428571 0.26285714 0.26285714 0.28428571 0.26285714 0.26285714\n",
            "        nan        nan        nan 0.25015873 0.32238095 0.32238095\n",
            " 0.25015873 0.32238095 0.32238095 0.26111111 0.21428571 0.21428571\n",
            " 0.2817094  0.27444444 0.2817094  0.2817094  0.27444444 0.2817094\n",
            " 0.28493827 0.28493827 0.29481481 0.2940388  0.30515721 0.2940388\n",
            " 0.30515721 0.33286033 0.32255073 0.30408425 0.28922559 0.30408425\n",
            " 0.28922559 0.30721501 0.30721501 0.31213321 0.31728131 0.31213321\n",
            " 0.31728131 0.31034753 0.29703704 0.29703704 0.27716049 0.27716049\n",
            " 0.29184735 0.28670465 0.29184735 0.28670465 0.30302477 0.30302477]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            " 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.63897108 0.69431379 0.72783903 0.63897108 0.69431379 0.72783903\n",
            "        nan        nan        nan 0.54644866 0.66390528 0.69130378\n",
            " 0.54644866 0.66390528 0.69130378 0.61454572 0.60805377 0.60805377\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.85459316 0.90108089 0.92078876\n",
            " 0.85459316 0.90108089 0.92078876        nan        nan        nan\n",
            " 0.85459316 0.90279078 0.91235628 0.85459316 0.90279078 0.91235628\n",
            " 0.89564032 0.94879403 0.94879403        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.98191231 1.         1.         0.98191231 1.         1.\n",
            "        nan        nan        nan 0.97355286 1.         1.\n",
            " 0.97355286 1.         1.         0.98505231 0.99164054 0.99164054\n",
            " 0.3265074  0.32462634 0.33274303 0.3265074  0.32462634 0.33274303\n",
            " 0.26848908 0.26848908 0.29544019 0.94666412 0.94732723 0.94666412\n",
            " 0.94732723 0.91474861 0.91704114 0.51193248 0.9626539  0.51193248\n",
            " 0.9626539  0.61637337 0.61637337 0.87624817 0.96039629 0.87624817\n",
            " 0.96039629 0.89536527 0.52749734 0.52749734 0.85904866 0.85904866\n",
            " 0.99246341 0.99246341 0.99246341 0.99246341 0.95029161 0.95029161]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 2\n",
            "n_candidates: 12\n",
            "n_resources: 270\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            " 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.31428571 0.27619048 0.26904762 0.31428571 0.27619048 0.26904762\n",
            "        nan        nan        nan 0.27619048 0.26904762 0.26904762\n",
            " 0.27619048 0.26904762 0.26904762 0.25571429 0.26904762 0.26904762\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.28428571 0.27619048 0.27619048\n",
            " 0.28428571 0.27619048 0.27619048        nan        nan        nan\n",
            " 0.32238095 0.27619048 0.33571429 0.32238095 0.27619048 0.33571429\n",
            " 0.29301587 0.27619048 0.27619048        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.28428571 0.26285714 0.26285714 0.28428571 0.26285714 0.26285714\n",
            "        nan        nan        nan 0.25015873 0.32238095 0.32238095\n",
            " 0.25015873 0.32238095 0.32238095 0.26111111 0.21428571 0.21428571\n",
            " 0.2817094  0.27444444 0.2817094  0.2817094  0.27444444 0.2817094\n",
            " 0.28493827 0.28493827 0.29481481 0.2940388  0.30515721 0.2940388\n",
            " 0.30515721 0.33286033 0.32255073 0.30408425 0.28922559 0.30408425\n",
            " 0.28922559 0.30721501 0.30721501 0.31213321 0.31728131 0.31213321\n",
            " 0.31728131 0.31034753 0.29703704 0.29703704 0.27716049 0.27716049\n",
            " 0.29184735 0.28670465 0.29184735 0.28670465 0.30302477 0.30302477\n",
            " 0.26483693 0.26780476 0.26780476 0.24957317 0.24957317 0.27866758\n",
            " 0.3078505  0.3078505  0.29606532 0.29606532 0.28623787 0.29286055]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            " 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.63897108 0.69431379 0.72783903 0.63897108 0.69431379 0.72783903\n",
            "        nan        nan        nan 0.54644866 0.66390528 0.69130378\n",
            " 0.54644866 0.66390528 0.69130378 0.61454572 0.60805377 0.60805377\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.85459316 0.90108089 0.92078876\n",
            " 0.85459316 0.90108089 0.92078876        nan        nan        nan\n",
            " 0.85459316 0.90279078 0.91235628 0.85459316 0.90279078 0.91235628\n",
            " 0.89564032 0.94879403 0.94879403        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.98191231 1.         1.         0.98191231 1.         1.\n",
            "        nan        nan        nan 0.97355286 1.         1.\n",
            " 0.97355286 1.         1.         0.98505231 0.99164054 0.99164054\n",
            " 0.3265074  0.32462634 0.33274303 0.3265074  0.32462634 0.33274303\n",
            " 0.26848908 0.26848908 0.29544019 0.94666412 0.94732723 0.94666412\n",
            " 0.94732723 0.91474861 0.91704114 0.51193248 0.9626539  0.51193248\n",
            " 0.9626539  0.61637337 0.61637337 0.87624817 0.96039629 0.87624817\n",
            " 0.96039629 0.89536527 0.52749734 0.52749734 0.85904866 0.85904866\n",
            " 0.99246341 0.99246341 0.99246341 0.99246341 0.95029161 0.95029161\n",
            " 0.5209085  0.88526768 0.88526768 0.60761598 0.60761598 0.73142837\n",
            " 0.82317191 0.82317191 0.96506122 0.96506122 0.83646442 0.84225255]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "iter: 3\n",
            "n_candidates: 4\n",
            "n_resources: 810\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            " 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762 0.26904762\n",
            " 0.26904762 0.26904762 0.26904762        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.31428571 0.27619048 0.26904762 0.31428571 0.27619048 0.26904762\n",
            "        nan        nan        nan 0.27619048 0.26904762 0.26904762\n",
            " 0.27619048 0.26904762 0.26904762 0.25571429 0.26904762 0.26904762\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.28428571 0.27619048 0.27619048\n",
            " 0.28428571 0.27619048 0.27619048        nan        nan        nan\n",
            " 0.32238095 0.27619048 0.33571429 0.32238095 0.27619048 0.33571429\n",
            " 0.29301587 0.27619048 0.27619048        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.28428571 0.26285714 0.26285714 0.28428571 0.26285714 0.26285714\n",
            "        nan        nan        nan 0.25015873 0.32238095 0.32238095\n",
            " 0.25015873 0.32238095 0.32238095 0.26111111 0.21428571 0.21428571\n",
            " 0.2817094  0.27444444 0.2817094  0.2817094  0.27444444 0.2817094\n",
            " 0.28493827 0.28493827 0.29481481 0.2940388  0.30515721 0.2940388\n",
            " 0.30515721 0.33286033 0.32255073 0.30408425 0.28922559 0.30408425\n",
            " 0.28922559 0.30721501 0.30721501 0.31213321 0.31728131 0.31213321\n",
            " 0.31728131 0.31034753 0.29703704 0.29703704 0.27716049 0.27716049\n",
            " 0.29184735 0.28670465 0.29184735 0.28670465 0.30302477 0.30302477\n",
            " 0.26483693 0.26780476 0.26780476 0.24957317 0.24957317 0.27866758\n",
            " 0.3078505  0.3078505  0.29606532 0.29606532 0.28623787 0.29286055\n",
            " 0.30769578 0.30769578 0.30348962 0.30348962]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            " 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178 0.24244178\n",
            " 0.24244178 0.24244178 0.24244178        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.63897108 0.69431379 0.72783903 0.63897108 0.69431379 0.72783903\n",
            "        nan        nan        nan 0.54644866 0.66390528 0.69130378\n",
            " 0.54644866 0.66390528 0.69130378 0.61454572 0.60805377 0.60805377\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.85459316 0.90108089 0.92078876\n",
            " 0.85459316 0.90108089 0.92078876        nan        nan        nan\n",
            " 0.85459316 0.90279078 0.91235628 0.85459316 0.90279078 0.91235628\n",
            " 0.89564032 0.94879403 0.94879403        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.98191231 1.         1.         0.98191231 1.         1.\n",
            "        nan        nan        nan 0.97355286 1.         1.\n",
            " 0.97355286 1.         1.         0.98505231 0.99164054 0.99164054\n",
            " 0.3265074  0.32462634 0.33274303 0.3265074  0.32462634 0.33274303\n",
            " 0.26848908 0.26848908 0.29544019 0.94666412 0.94732723 0.94666412\n",
            " 0.94732723 0.91474861 0.91704114 0.51193248 0.9626539  0.51193248\n",
            " 0.9626539  0.61637337 0.61637337 0.87624817 0.96039629 0.87624817\n",
            " 0.96039629 0.89536527 0.52749734 0.52749734 0.85904866 0.85904866\n",
            " 0.99246341 0.99246341 0.99246341 0.99246341 0.95029161 0.95029161\n",
            " 0.5209085  0.88526768 0.88526768 0.60761598 0.60761598 0.73142837\n",
            " 0.82317191 0.82317191 0.96506122 0.96506122 0.83646442 0.84225255\n",
            " 0.93598977 0.93598977 0.82083093 0.82083093]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusi√≥n: \n",
            "\n",
            "[[ 14  61   2]\n",
            " [ 22 129   5]\n",
            " [  0  21   3]]\n",
            "\n",
            "Reporte de Clasificaci√≥n: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.39      0.18      0.25        77\n",
            "        Good       0.61      0.83      0.70       156\n",
            "     Neutral       0.30      0.12      0.18        24\n",
            "\n",
            "    accuracy                           0.57       257\n",
            "   macro avg       0.43      0.38      0.38       257\n",
            "weighted avg       0.52      0.57      0.52       257\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37575182468637425"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgs2.best_params_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itT9leqbfqB7",
        "outputId": "360b179b-567c-4d79-c015-cf410f5cc112"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__C': 100,\n",
              " 'preprocessing__BoW__max_df': 1,\n",
              " 'preprocessing__BoW__min_df': 0,\n",
              " 'preprocessing__BoW__ngram_range': (1, 1),\n",
              " 'selection__percentile': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reporte la mejor combinaci√≥n encontrada y justifique por qu√© cree que es la mejor seg√∫n el clasificador usado, la cantidad de columnas seleccionadas y los par√°metros de CountVectorizer seleccionados por GridSearch.\n",
        "\n",
        "Se elige el clasificador de svm.SVC con el √∫nico par√°metro variado de C igual a 100 y con valores de CountVectorizer con 1-ngram, con df_max=1 y df_min=0. Y por √∫ltimo en cuando al Selectionpercentile, el elegido es el de 40.\n",
        "\n",
        "La raz√≥n para elegir este clasificador es porque es el que da un mejor valor de F1-Score en comparaci√≥n a los otros modelos. Se elige la m√©trica F1-Score debido a que nos interesan todos los tipos de las etiquetas, y esa m√©trica calcula un ponderado de las clases positivas que realmente nos interesan."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "807d969e26fc4b049be6482e527b12a4",
        "deepnote_cell_height": 70.796875,
        "deepnote_cell_type": "markdown",
        "id": "LnUDVfOS4PQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Predicci√≥n del datos sin etiquetado  [0.5 puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "OmQUw2aZ_6z2",
        "cell_id": "e4fd03fac45b4d288f6c67f8bbbf8c18",
        "deepnote_cell_height": 600.15625,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLego el momento de predecir\n",
        "`Vergil`, `Gorilla Girl` y `Batcow`\n",
        "\n",
        "\n",
        "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
      ],
      "metadata": {
        "id": "Cj0ERBgTBFWN",
        "cell_id": "7f4aa54f58fd436f99c206aab5be6850",
        "deepnote_cell_height": 111.171875,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Respuesta:**"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "6c3937a8832f4c48bbad30dc1b27d42d",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "ISNzgq0k4PQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "TnB06bujnPsB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'model__C': 100,\n",
        " 'preprocessing__BoW__max_df': 1,\n",
        " 'preprocessing__BoW__min_df': 0,\n",
        " 'preprocessing__BoW__ngram_range': (1, 1),\n",
        " 'selection__percentile': 40}"
      ],
      "metadata": {
        "id": "lYWLrtxhmHA-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Configuraciones de BoW ###\n",
        "bow2 = CountVectorizer(tokenizer = StemmerTokenizer(),\n",
        "                      ngram_range= params['preprocessing__BoW__ngram_range'],\n",
        "                      max_df=params['preprocessing__BoW__max_df'],\n",
        "                      min_df=params['preprocessing__BoW__min_df']\n",
        "                      )"
      ],
      "metadata": {
        "id": "i5I5J25Tkm-I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocesador1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('BoW', bow2, text),\n",
        "        ('MinMax', minmax, atributos_de_interes),\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    sparse_threshold=0\n",
        "    )"
      ],
      "metadata": {
        "id": "ECgCMrtYkxKH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### C√≥digo aqu√≠ ####\n",
        "clasificador = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessing\", preprocesador1),\n",
        "        (\"selection\", SelectPercentile(f_classif, percentile=params['selection__percentile'])),\n",
        "        (\"model\", svm.SVC(C=params['model__C'])),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "56ba92e787044d4c9064a0bd5341842d",
        "deepnote_cell_height": 66,
        "deepnote_cell_type": "code",
        "id": "yzjFIyh44PQ0"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_comics.drop(['alignment', 'name',\t'real_name',\t'full_name', \t'powers_text'], axis=1)\n",
        "y = df_comics['alignment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=190423)"
      ],
      "metadata": {
        "id": "E0PC0VBBl4jc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clasificador.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "50vJVPA8nZAU",
        "outputId": "c74a59dc-15d2-48f7-93b4-d97522651361"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessing',\n",
              "                 ColumnTransformer(sparse_threshold=0,\n",
              "                                   transformers=[('BoW',\n",
              "                                                  CountVectorizer(max_df=1,\n",
              "                                                                  min_df=0,\n",
              "                                                                  tokenizer=<__main__.StemmerTokenizer object at 0x7f4047e3f670>),\n",
              "                                                  'history_text'),\n",
              "                                                 ('MinMax', MinMaxScaler(),\n",
              "                                                  ['intelligence_score',\n",
              "                                                   'strength_score',\n",
              "                                                   'speed_score',\n",
              "                                                   'durability_score',\n",
              "                                                   'power_score',\n",
              "                                                   'combat_score'])])),\n",
              "                ('selection', SelectPercentile(percentile=40)),\n",
              "                ('model', SVC(C=100))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 ColumnTransformer(sparse_threshold=0,\n",
              "                                   transformers=[(&#x27;BoW&#x27;,\n",
              "                                                  CountVectorizer(max_df=1,\n",
              "                                                                  min_df=0,\n",
              "                                                                  tokenizer=&lt;__main__.StemmerTokenizer object at 0x7f4047e3f670&gt;),\n",
              "                                                  &#x27;history_text&#x27;),\n",
              "                                                 (&#x27;MinMax&#x27;, MinMaxScaler(),\n",
              "                                                  [&#x27;intelligence_score&#x27;,\n",
              "                                                   &#x27;strength_score&#x27;,\n",
              "                                                   &#x27;speed_score&#x27;,\n",
              "                                                   &#x27;durability_score&#x27;,\n",
              "                                                   &#x27;power_score&#x27;,\n",
              "                                                   &#x27;combat_score&#x27;])])),\n",
              "                (&#x27;selection&#x27;, SelectPercentile(percentile=40)),\n",
              "                (&#x27;model&#x27;, SVC(C=100))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 ColumnTransformer(sparse_threshold=0,\n",
              "                                   transformers=[(&#x27;BoW&#x27;,\n",
              "                                                  CountVectorizer(max_df=1,\n",
              "                                                                  min_df=0,\n",
              "                                                                  tokenizer=&lt;__main__.StemmerTokenizer object at 0x7f4047e3f670&gt;),\n",
              "                                                  &#x27;history_text&#x27;),\n",
              "                                                 (&#x27;MinMax&#x27;, MinMaxScaler(),\n",
              "                                                  [&#x27;intelligence_score&#x27;,\n",
              "                                                   &#x27;strength_score&#x27;,\n",
              "                                                   &#x27;speed_score&#x27;,\n",
              "                                                   &#x27;durability_score&#x27;,\n",
              "                                                   &#x27;power_score&#x27;,\n",
              "                                                   &#x27;combat_score&#x27;])])),\n",
              "                (&#x27;selection&#x27;, SelectPercentile(percentile=40)),\n",
              "                (&#x27;model&#x27;, SVC(C=100))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(sparse_threshold=0,\n",
              "                  transformers=[(&#x27;BoW&#x27;,\n",
              "                                 CountVectorizer(max_df=1, min_df=0,\n",
              "                                                 tokenizer=&lt;__main__.StemmerTokenizer object at 0x7f4047e3f670&gt;),\n",
              "                                 &#x27;history_text&#x27;),\n",
              "                                (&#x27;MinMax&#x27;, MinMaxScaler(),\n",
              "                                 [&#x27;intelligence_score&#x27;, &#x27;strength_score&#x27;,\n",
              "                                  &#x27;speed_score&#x27;, &#x27;durability_score&#x27;,\n",
              "                                  &#x27;power_score&#x27;, &#x27;combat_score&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BoW</label><div class=\"sk-toggleable__content\"><pre>history_text</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=1, min_df=0,\n",
              "                tokenizer=&lt;__main__.StemmerTokenizer object at 0x7f4047e3f670&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMax</label><div class=\"sk-toggleable__content\"><pre>[&#x27;intelligence_score&#x27;, &#x27;strength_score&#x27;, &#x27;speed_score&#x27;, &#x27;durability_score&#x27;, &#x27;power_score&#x27;, &#x27;combat_score&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=40)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nombre_predic=['Vergil', 'Gorilla Girl', 'Batcow']"
      ],
      "metadata": {
        "id": "DHJtAKlvoKln"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_prediccion=df_comics_no_label[df_comics_no_label['name'].isin(nombre_predic)]"
      ],
      "metadata": {
        "id": "QxcLNzmxnn2k"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_prediccion=X_prediccion.iloc[:3]"
      ],
      "metadata": {
        "id": "-nvG19F2o5qH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_prediccion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "YWZnpORtphjY",
        "outputId": "61e8e802-09c6-4964-9e3e-588167d89cd7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0          name        real_name        full_name overall_score  \\\n",
              "16         122        Batcow             None             None             3   \n",
              "40         529  Gorilla Girl  Fahnbullah Eddy  Fahnbullah Eddy             7   \n",
              "78        1368        Vergil    Vergil Sparda              NaN            16   \n",
              "\n",
              "                                         history_text  \\\n",
              "16  Bat-Cow was originally a cow that was found by...   \n",
              "40  A carnival performer with the ability to turn ...   \n",
              "78  Vergil, later also known as Nelo Angelo, is on...   \n",
              "\n",
              "                                          powers_text  intelligence_score  \\\n",
              "16                                                NaN                  70   \n",
              "40  Gorilla Girl can transform into a talking gori...                  90   \n",
              "78                                                NaN                  90   \n",
              "\n",
              "    strength_score  speed_score  ...  has_flight  has_accelerated_healing  \\\n",
              "16              10           25  ...         0.0                      0.0   \n",
              "40              35           60  ...         0.0                      0.0   \n",
              "78              75           95  ...         0.0                      1.0   \n",
              "\n",
              "    has_weapons_master has_intelligence has_reflexes has_super_speed  \\\n",
              "16                 0.0              0.0          0.0             0.0   \n",
              "40                 0.0              0.0          0.0             0.0   \n",
              "78                 1.0              1.0          1.0             1.0   \n",
              "\n",
              "   has_durability has_stamina has_agility  has_super_strength  \n",
              "16            0.0         0.0         0.0                 0.0  \n",
              "40            0.0         0.0         1.0                 1.0  \n",
              "78            1.0         1.0         1.0                 1.0  \n",
              "\n",
              "[3 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36d5e310-1c54-47a1-8b40-a6dd1dfcc31c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>real_name</th>\n",
              "      <th>full_name</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>history_text</th>\n",
              "      <th>powers_text</th>\n",
              "      <th>intelligence_score</th>\n",
              "      <th>strength_score</th>\n",
              "      <th>speed_score</th>\n",
              "      <th>...</th>\n",
              "      <th>has_flight</th>\n",
              "      <th>has_accelerated_healing</th>\n",
              "      <th>has_weapons_master</th>\n",
              "      <th>has_intelligence</th>\n",
              "      <th>has_reflexes</th>\n",
              "      <th>has_super_speed</th>\n",
              "      <th>has_durability</th>\n",
              "      <th>has_stamina</th>\n",
              "      <th>has_agility</th>\n",
              "      <th>has_super_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>122</td>\n",
              "      <td>Batcow</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>Bat-Cow was originally a cow that was found by...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>529</td>\n",
              "      <td>Gorilla Girl</td>\n",
              "      <td>Fahnbullah Eddy</td>\n",
              "      <td>Fahnbullah Eddy</td>\n",
              "      <td>7</td>\n",
              "      <td>A carnival performer with the ability to turn ...</td>\n",
              "      <td>Gorilla Girl can transform into a talking gori...</td>\n",
              "      <td>90</td>\n",
              "      <td>35</td>\n",
              "      <td>60</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1368</td>\n",
              "      <td>Vergil</td>\n",
              "      <td>Vergil Sparda</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>Vergil, later also known as Nelo Angelo, is on...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>75</td>\n",
              "      <td>95</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows √ó 82 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36d5e310-1c54-47a1-8b40-a6dd1dfcc31c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36d5e310-1c54-47a1-8b40-a6dd1dfcc31c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36d5e310-1c54-47a1-8b40-a6dd1dfcc31c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clasificador.predict(X_prediccion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfT4x6LppNNZ",
        "outputId": "157b2695-d18d-4b6a-c3da-4c0c2d3bd593"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bad', 'Good', 'Neutral'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# El Batcow es Bad La Gorilla Girl es Good y Vergil es Neutral"
      ],
      "metadata": {
        "id": "GSMGPtC1pbLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "Rg4ZMq8ezAH6",
        "cell_id": "0ee55c847633405fb2e7cfaade1fc799",
        "deepnote_cell_height": 269,
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ],
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "gPMzcfJu4PQ1"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "toc": {
      "sideBar": true,
      "nav_menu": {},
      "toc_cell": false,
      "title_cell": "Tabla de Contenidos",
      "toc_position": {
        "top": "150px",
        "left": "10px",
        "width": "241.867px",
        "height": "calc(100% - 180px)"
      },
      "skip_h1_title": true,
      "title_sidebar": "Contenidos",
      "base_numbering": 1,
      "number_sections": true,
      "toc_window_display": true,
      "toc_section_display": true
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LCOUC4jss148",
        "GtG74Cphq56p"
      ]
    },
    "deepnote": {},
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "varInspector": {
      "cols": {
        "lenVar": 40,
        "lenName": 16,
        "lenType": 16
      },
      "kernels_config": {
        "r": {
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) ",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") "
        },
        "python": {
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": ""
        }
      },
      "window_display": false,
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    },
    "deepnote_notebook_id": "b7ffc7ddb4f14fcd976082c27e48a913",
    "deepnote_execution_queue": []
  }
}
